import pandas as pd
import joblib
import os
import warnings

from tqdm import tqdm
from features_v2 import FeatureExtraction
from externel_service_features import (
    extract_domain,
    google_safe_browsing_check,
    detect_bitdefender,
    whois_registered,
    download_latest_tranco,
    tranco_rank
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
warnings.filterwarnings("ignore")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ê²½ë¡œ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
MODEL_PATH = os.path.join(BASE_DIR, "mvc_model.pkl")
PREPROCESSOR_PATH = os.path.join(BASE_DIR, "preprocessor.pkl")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ëª¨ë¸ ë° ì „ì²˜ë¦¬ ë¡œë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
model = joblib.load(MODEL_PATH)
preprocessor = joblib.load(PREPROCESSOR_PATH)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì •ì  íŠ¹ì§• tqdm â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
STATIC_FEATURE_NAMES = [
    "uses_ip_address", "is_url_too_long", "uses_shortening_service", "has_at_symbol",
    "has_prefix_suffix_in_domain", "has_many_subdomains", "has_https_in_scheme",
    "has_external_favicon", "check_external_resource_ratio", "check_anchor_tag_safety",
    "check_script_link_ratio", "check_form_handler", "has_email_submission",
    "check_website_forwarding", "uses_popup_window", "has_iframe_redirection",
    "check_links_pointing_to_page", "has_suspicious_words_in_url", "count_digits_in_url",
    "meta_refresh_exists", "has_password_input", "external_script_ratio"
]

def extract_static_features_with_tqdm(url):
    extractor = FeatureExtraction(url)
    features = []
    pbar = tqdm(total=len(STATIC_FEATURE_NAMES), desc="ğŸ“˜ ì •ì  íŠ¹ì§• ì¶”ì¶œ ì§„í–‰", ncols=100)
    for name in STATIC_FEATURE_NAMES:
        features.append(getattr(extractor, name)())
        pbar.update(1)
    pbar.close()
    return features

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì™¸ë¶€ ì„œë¹„ìŠ¤ íŠ¹ì§• tqdm â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def get_external_features_with_cache(url):
    domain = extract_domain(url)
    steps = [
        "Google Safe Browsing",
        "Bitdefender TrafficLight",
        "WHOIS ë“±ë¡ ì—¬ë¶€",
        "Tranco Rank"
    ]
    pbar = tqdm(total=len(steps), desc="ğŸŒ ì™¸ë¶€ íŠ¹ì§• ì¶”ì¶œ ì§„í–‰", ncols=100)

    gsb = google_safe_browsing_check(url)
    pbar.update(1)
    bd = detect_bitdefender(domain)[1]
    pbar.update(1)
    whois_r = whois_registered(domain)
    pbar.update(1)

    tranco_dict = download_latest_tranco()
    tranco_r = tranco_rank(domain, tranco_dict)
    pbar.update(1)
    pbar.close()

    return [gsb, tranco_r, bd, whois_r]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì˜ˆì¸¡ í•¨ìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def predict_url_phishing(url):
    print(f"\nğŸ” ì…ë ¥ëœ URL: {url}")
    static_features = extract_static_features_with_tqdm(url)
    external_features = get_external_features_with_cache(url)
    full_features = static_features + external_features

    df_input = pd.DataFrame([full_features], columns=preprocessor.feature_names_in_)
    scaled_features = preprocessor.transform(df_input)
    df_scaled = pd.DataFrame(scaled_features, columns=preprocessor.feature_names_in_)

    prediction = model.predict(df_scaled)[0]
    return "ğŸ”´ í”¼ì‹± ì‚¬ì´íŠ¸" if prediction == -1 else "ğŸŸ¢ ì •ìƒ ì‚¬ì´íŠ¸"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì‚¬ìš©ì ì…ë ¥ ê¸°ë°˜ ì‹¤í–‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    url = input("ğŸ” ê²€ì‚¬í•  URLì„ ì…ë ¥í•˜ì„¸ìš”: ").strip()
    if url:
        result = predict_url_phishing(url)
        print(f"\n[ê²°ê³¼] {url} â†’ {result}")
    else:
        print("â— URLì„ ì…ë ¥í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
